{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f10d5ba8",
   "metadata": {},
   "source": [
    "# get_fdt test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dd12c3",
   "metadata": {},
   "source": [
    "## TO-DO\n",
    "- sort by values or by index\n",
    "- fmt_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38fb7b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard Libs\n",
    "from typing import Union, Optional, Tuple, Literal, Any\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "# Third-Party Libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import seaborn as sns\n",
    "\n",
    "# # Local Libs\n",
    "# from jm_datascience import jm_pandas as jm_pd\n",
    "# from jm_datascience import jm_pdaccessor as jm\n",
    "# from jm_utils import jm_richprt as jm_prt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3282540",
   "metadata": {},
   "source": [
    "## Some Series and DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4919c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_work = pd.DataFrame({\n",
    "    'nombre': ['Ana', 'Bob', '', 'Carlos', ' ', 'Diana'],\n",
    "    'apellido': ['A_Ana', 'B_Bob', None, 'C_Carlos', None, 'D_Diana'],\n",
    "    'edad': [25, -1, 30, 999, 28, 22],\n",
    "    'ciudad': ['Madrid', 'N/A', 'Barcelona', 'Valencia', 'unknown', 'Sevilla'],\n",
    "    'salario': [50000, 0, 60000, -999, 55000, 48000]\n",
    "})\n",
    "\n",
    "## Read spreedsheet for tests\n",
    "try:\n",
    "    spreedsheet = r\"C:\\Users\\jm\\Documents\\__Dev\\PortableGit\\__localrepos\\365DS_jm\\3_statistics\\2_13_Practical_Ex_Descriptive_Stats.xlsx\"    # Casa\n",
    "    with open(spreedsheet) as f:\n",
    "        pass\n",
    "except FileNotFoundError:\n",
    "    spreedsheet = r\"D:\\git\\PortableGit\\__localrepos\\365DS_jm\\3_statistics\\2_13_Practical_Ex_Descriptive_Stats.xlsx\"                         # Office\n",
    "\n",
    "df_xls = pd.read_excel(spreedsheet, skiprows=4, usecols='B:J,L:AA', index_col='ID')\n",
    "df = df_xls.copy()\n",
    "\n",
    "lst_str = random.choices([chr(i) for i in range(65, 72)], k=175)\n",
    "# sr_str = jm_pd.to_series(lst_str)                         # <- jm_pd.to_serie_with_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f9cee95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['California', 'Virginia', 'Arizona', 'Oregon', 'Nevada',\n",
       "       'Colorado', 'Utah', nan, 'Kansas', 'Wyoming'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Country\n",
       "Germany      1\n",
       "Mexico       1\n",
       "Denmark      1\n",
       "UK           2\n",
       "Belgium      2\n",
       "Russia       4\n",
       "Canada       7\n",
       "USA         12\n",
       "NaN         72\n",
       "USA        165\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(df['State'].unique())\n",
    "df['State'].value_counts(sort=False, ascending=True)\n",
    "df['Country'].value_counts(sort=True, ascending=True, dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ad6c3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fmt_value_for_pd(value, width=8, decimals=3, miles=',') -> str:\n",
    "    \"\"\"\n",
    "    Format a value (numeric or string) into a right-aligned string of fixed width.\n",
    "\n",
    "    Converts numeric values to formatted strings with thousands separators and\n",
    "    specified decimal places. Strings are padded to the same width for consistent alignment.\n",
    "\n",
    "    Parameters:\n",
    "        value (int, float, str): The value to be formatted.\n",
    "        width (int): Total width of the output string. Must be a positive integer.\n",
    "        decimals (int): Number of decimal places for numeric values. Must be >= 0.\n",
    "        miles (str or None): Thousands separator. Valid options: ',', '_', or None.\n",
    "\n",
    "    Returns:\n",
    "        str: The formatted string with right alignment.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If width <= 0, decimals < 0, or miles is invalid.\n",
    "\n",
    "    Examples:\n",
    "        >>> format_value(123456.789)\n",
    "        '123,456.79'\n",
    "        >>> format_value(\"text\", width=10)\n",
    "        '      text'\n",
    "        >>> format_value(9876, miles=None)\n",
    "        '    9876.00'\n",
    "    \"\"\"\n",
    "    # Parameter Value validation <- vamos a tener que analizar este tema por si es un list , etc,,\n",
    "    #   - En realidad acá tenemos que evaluar algo similar a jm_utils - fmt_values() FUTURE\n",
    "    # if not isinstance(value, (int, float, np.integer, np.floating)) or pd.api.types.is_any_real_numeric_dtype(value)\n",
    "\n",
    "    if not isinstance(width, int) or width <= 0:\n",
    "        raise ValueError(f\"Width must be a positive integer. Not '{width}'\")\n",
    "    \n",
    "    if not isinstance(decimals, int) or decimals < 0:\n",
    "        raise ValueError(f\"Decimals must be a non-negative integer. Not '{decimals}\")\n",
    "    \n",
    "    if miles not in [',', '_', None]:\n",
    "        raise ValueError(f\"Miles must be either ',', '_', or None. Not '{miles}\")\n",
    "    \n",
    "    try:\n",
    "        num = float(value)                                  # Convert to float if possible\n",
    "        if num % 1 == 0:                                    # it its a total integer number\n",
    "            decimals = 0\n",
    "        if miles:\n",
    "            return f\"{num:>{width}{miles}.{decimals}f}\"     # Ancho fijo, x decimales, alineado a la derecha\n",
    "        else:\n",
    "            return f\"{num:>{width}.{decimals}f}\"\n",
    "        \n",
    "    except (ValueError, TypeError):\n",
    "        return str(value).rjust(width)                      # Alinea también strings, para mantener la grilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe510044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_series(\n",
    "    data: Union[pd.Series, np.ndarray, dict, list, set, pd.DataFrame],\n",
    "    index: Optional[pd.Index] = None,\n",
    "    name: Optional[str] = None\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Converts input data into a pandas Series, optionally returning value counts.\n",
    "\n",
    "    This function accepts various data types and converts them into a pandas Series.\n",
    "    If `count=True`, it returns the frequency count of the values in the resulting Series.\n",
    "\n",
    "    Parameters:\n",
    "        data (Union[pd.Series, np.ndarray, dict, list, set, pd.DataFrame]):\n",
    "            The input data to convert. Supported types include:\n",
    "            - pd.Series: returned as-is or counted if `count=True`.\n",
    "            - np.ndarray: flattened and converted to a Series.\n",
    "            - dict: keys become the index, values are used for data.\n",
    "            - list or set: converted directly to a Series.\n",
    "            - pd.DataFrame:\n",
    "                - 1 column: converted directly to a Series.\n",
    "                - 2 columns: first column becomes the index, second becomes the values.\n",
    "\n",
    "        count (bool or int, optional): Whether to return value counts instead of raw data.\n",
    "            If True or 1, returns frequencies of each value. Default is False.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: A pandas Series representing the input data. If `count=True`, returns\n",
    "            the value counts of the data.\n",
    "\n",
    "    Raises:\n",
    "        TypeError: If `data` is not one of the supported types.\n",
    "        ValueError: If `count` is not a boolean or integer 0/1.\n",
    "        ValueError: If DataFrame has more than 2 columns.\n",
    "\n",
    "    Examples:\n",
    "        >>> import pandas as pd\n",
    "        >>> to_serie_with_count([1, 2, 2, 3])\n",
    "        0    1\n",
    "        1    2\n",
    "        2    2\n",
    "        3    3\n",
    "        dtype: int64\n",
    "\n",
    "        >>> to_serie_with_count([1, 2, 2, 3], count=True)\n",
    "        2    2\n",
    "        1    1\n",
    "        3    1\n",
    "        dtype: int64\n",
    "\n",
    "        >>> df = pd.DataFrame({'Category': ['A', 'B', 'A'], 'Value': [10, 20, 30]})\n",
    "        >>> to_serie_with_count(df)\n",
    "        Category\n",
    "        A    10\n",
    "        B    20\n",
    "        A    30\n",
    "        Name: Value, dtype: int64\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate parameters - FUTURE\n",
    "    \n",
    "    if isinstance(data, pd.Series):                 # If data is already a series no conversion needed\n",
    "        sr = data                                  \n",
    "    elif isinstance(data, np.ndarray):              # If data is a NumPy array   \n",
    "        sr = pd.sr(data.flatten())\n",
    "    elif isinstance(data, (dict, list)):\n",
    "        sr = pd.sr(data)\n",
    "    elif isinstance(data, (set)):\n",
    "        sr = pd.sr(tuple(data))\n",
    "    elif isinstance(data, pd.DataFrame):\n",
    "        if data.shape[1] == 1:                      # Also len(data.columns == 1)\n",
    "            sr = data.iloc[:, 0]\n",
    "        elif data.shape[1] == 2:                    # Index: first col, Data: 2nd Col\n",
    "            sr = data.set_index(data.columns[0])[data.columns[1]]\n",
    "        else:\n",
    "            raise ValueError(\"DataFrame must have 1 oer 2 columns. Categories and values for 2 columns cases.\")\n",
    "    else:\n",
    "        raise TypeError(f\"Unsupported data type: {type(data)}. \"\n",
    "                    \"Supported types: pd.sr, np.ndarray, pd.DataFrame, dict, list, set, and pd.DataFrame\")\n",
    "\n",
    "    if name:\n",
    "        sr.name = name\n",
    "\n",
    "    if index:\n",
    "        sr.index = index\n",
    "\n",
    "    return sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb7068fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fdt(\n",
    "        data: Union[pd.Series, np.ndarray, dict, list, pd.DataFrame],\n",
    "        value_counts: Optional[bool] = False,\n",
    "        dropna: Optional[bool] = True,\n",
    "        na_position: Optional[str] = 'last',\n",
    "        pcts: Optional[bool] = True,\n",
    "        plain_relatives: Optional[bool] = True,\n",
    "        fmt_values: Optional[bool] = False,\n",
    "        sort: Optional[str] = 'desc',\n",
    "        na_aside: Optional[bool] = True\n",
    ") -> pd.DataFrame:\n",
    "    '''\n",
    "    Generata a Frequency Distribution Table (fdt)\n",
    "\n",
    "    data: puede ser ya con el value_counts() hecho o no\n",
    "    sort: 'desc', 'asc', 'ix_asc', 'ix_desc', para como queremos que sea vea el orden por valores o por indice\n",
    "    na_position: 'first', 'last', 'value'\n",
    "    '''\n",
    "    columns = [\n",
    "        'Frequency',\n",
    "        'Cumulative Frequency',\n",
    "        'Relative Frequency',\n",
    "        'Cumulative Relative Freq.',\n",
    "        'Relative Freq. [%]',\n",
    "        'Cumulative Freq. [%]'\n",
    "    ]\n",
    "    # def _calculate_fdt_relatives(series):     # Revisar, no me gusta el flujo actual\n",
    "    \n",
    "    sr = to_series(data)\n",
    "    \n",
    "    if dropna:\n",
    "        sr = sr.dropna()\n",
    "\n",
    "    if value_counts:\n",
    "        sr = sr.value_counts(dropna=dropna, sort=False)\n",
    "\n",
    "    match sort:\n",
    "        case 'asc':\n",
    "            sr = sr.sort_values()\n",
    "        case 'desc':\n",
    "            sr = sr.sort_values(ascending=False)\n",
    "        case 'ix_asc':\n",
    "            sr = sr.sort_index()\n",
    "        case 'ix_desc':\n",
    "            sr = sr.sort_index(ascending=False)\n",
    "        case None:\n",
    "            pass\n",
    "        case _:\n",
    "            raise ValueError(f\"Valid values for sort: 'asc', 'desc', 'ix_asc', 'ix_desc', or None. Got '{sort}'\")\n",
    "\n",
    "    try:                            # To manage when there aren't NaNs\n",
    "        nan_value = sr[np.nan]\n",
    "        sr_without_nan = sr.drop(np.nan)\n",
    "    except:\n",
    "        pass\n",
    "    else:                           # if NaNs: 1. na_position, 2 na_count\n",
    "        match na_position:          # 1. locate the NaNs values\n",
    "            case 'first':\n",
    "                sr = pd.concat([pd.Series({np.nan: nan_value}), sr_without_nan])\n",
    "            case 'last':\n",
    "                sr = pd.concat([sr_without_nan, pd.Series({np.nan: nan_value})])\n",
    "            case 'value' | None:\n",
    "                pass\n",
    "            case _:\n",
    "                raise ValueError(f\"Valid values for na_position: 'first', 'last', 'value' or None. Got '{na_position}'\")\n",
    "        \n",
    "        if na_aside:                # 2. define if NaNs count for relative and cumulative values.\n",
    "            sr = sr_without_nan     # series without nulls on which the relative values will be calculated\n",
    "            # Column that will then be concatenated to the end of the DF if the na_aside option is true\n",
    "            nan_row_df = pd.DataFrame(data = [nan_value], columns=[columns[0]], index=['Nulls'])      # Only 'Frequency' column, others empty\n",
    "\n",
    "    fdt = pd.DataFrame(sr)\n",
    "    fdt.columns = [columns[0]]\n",
    "    fdt[columns[1]] = fdt['Frequency'].cumsum()\n",
    "    fdt[columns[2]] = fdt['Frequency'] / fdt['Frequency'].sum()\n",
    "    fdt[columns[3]] = fdt['Relative Frequency'].cumsum()\n",
    "    fdt[columns[4]] = fdt['Relative Frequency'] * 100\n",
    "    fdt[columns[5]] = fdt['Cumulative Relative Freq.'] * 100\n",
    "\n",
    "    if na_aside and not dropna:      # We add nan_columns at the end\n",
    "        fdt = pd.concat([fdt, nan_row_df])\n",
    "\n",
    "    if not pcts:                    # Don't return percentage columns\n",
    "        fdt = fdt[columns[0:4]]\n",
    "    \n",
    "    if not plain_relatives:         # Don't return relative and plain cumulative\n",
    "        fdt = fdt[[columns[0], columns[4], columns[5]]]\n",
    "\n",
    "    if fmt_values:\n",
    "        fdt = fdt.map(_fmt_value_for_pd)\n",
    "        \n",
    "    return fdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df9dd21e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Cumulative Frequency</th>\n",
       "      <th>Relative Frequency</th>\n",
       "      <th>Cumulative Relative Freq.</th>\n",
       "      <th>Relative Freq. [%]</th>\n",
       "      <th>Cumulative Freq. [%]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Germany</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mexico</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Denmark</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.375</td>\n",
       "      <td>1.124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UK</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.749</td>\n",
       "      <td>1.873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Belgium</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.749</td>\n",
       "      <td>2.622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Russia</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.041</td>\n",
       "      <td>1.498</td>\n",
       "      <td>4.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Canada</th>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.067</td>\n",
       "      <td>2.622</td>\n",
       "      <td>6.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USA</th>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.112</td>\n",
       "      <td>4.494</td>\n",
       "      <td>11.236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>72</td>\n",
       "      <td>102</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.382</td>\n",
       "      <td>26.966</td>\n",
       "      <td>38.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USA</th>\n",
       "      <td>165</td>\n",
       "      <td>267</td>\n",
       "      <td>0.618</td>\n",
       "      <td>1</td>\n",
       "      <td>61.798</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Frequency Cumulative Frequency Relative Frequency  \\\n",
       "Country                                                     \n",
       "Germany         1                    1              0.004   \n",
       "Mexico          1                    2              0.004   \n",
       "Denmark         1                    3              0.004   \n",
       "UK              2                    5              0.007   \n",
       "Belgium         2                    7              0.007   \n",
       "Russia          4                   11              0.015   \n",
       "Canada          7                   18              0.026   \n",
       "USA            12                   30              0.045   \n",
       "NaN            72                  102              0.270   \n",
       "USA           165                  267              0.618   \n",
       "\n",
       "        Cumulative Relative Freq. Relative Freq. [%] Cumulative Freq. [%]  \n",
       "Country                                                                    \n",
       "Germany                     0.004              0.375                0.375  \n",
       "Mexico                      0.007              0.375                0.749  \n",
       "Denmark                     0.011              0.375                1.124  \n",
       "UK                          0.019              0.749                1.873  \n",
       "Belgium                     0.026              0.749                2.622  \n",
       "Russia                      0.041              1.498                4.120  \n",
       "Canada                      0.067              2.622                6.742  \n",
       "USA                         0.112              4.494               11.236  \n",
       "NaN                         0.382             26.966               38.202  \n",
       "USA                             1             61.798                  100  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdt_s1 = get_fdt(df['Country'], value_counts=True, sort='asc', dropna=False, na_position='value', fmt_values=True, na_aside=False)\n",
    "fdt_s1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f238ec73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['119 (65.7 %)', '17 (9.4 %)', '11 (6.1 %)', '11 (6.1 %)', '11 (6.1 %)', '6 (3.3 %)', '4 (2.2 %)', '1 (0.6 %)', '1 (0.6 %)']\n",
      "cumulative_pcts.iloc[0] = 65.74585635359117\n",
      "cumulative_pcts.iloc[1] = 75.13812154696133\n",
      "cumulative_pcts.iloc[2] = 81.21546961325966\n",
      "cumulative_pcts.iloc[3] = 87.292817679558\n",
      "cumulative_pcts.iloc[4] = 93.37016574585634\n",
      "cumulative_pcts.iloc[5] = 96.68508287292816\n",
      "cumulative_pcts.iloc[6] = 98.89502762430938\n",
      "cumulative_pcts.iloc[7] = 99.44751381215468\n",
      "cumulative_pcts.iloc[8] = 99.99999999999997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(81.21546961325966)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Cumulative Frequency</th>\n",
       "      <th>Relative Frequency</th>\n",
       "      <th>Cumulative Relative Freq.</th>\n",
       "      <th>Relative Freq. [%]</th>\n",
       "      <th>Cumulative Freq. [%]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>0.657459</td>\n",
       "      <td>0.657459</td>\n",
       "      <td>65.745856</td>\n",
       "      <td>65.745856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nevada</th>\n",
       "      <td>17</td>\n",
       "      <td>136</td>\n",
       "      <td>0.093923</td>\n",
       "      <td>0.751381</td>\n",
       "      <td>9.392265</td>\n",
       "      <td>75.138122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arizona</th>\n",
       "      <td>11</td>\n",
       "      <td>147</td>\n",
       "      <td>0.060773</td>\n",
       "      <td>0.812155</td>\n",
       "      <td>6.077348</td>\n",
       "      <td>81.215470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oregon</th>\n",
       "      <td>11</td>\n",
       "      <td>158</td>\n",
       "      <td>0.060773</td>\n",
       "      <td>0.872928</td>\n",
       "      <td>6.077348</td>\n",
       "      <td>87.292818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colorado</th>\n",
       "      <td>11</td>\n",
       "      <td>169</td>\n",
       "      <td>0.060773</td>\n",
       "      <td>0.933702</td>\n",
       "      <td>6.077348</td>\n",
       "      <td>93.370166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utah</th>\n",
       "      <td>6</td>\n",
       "      <td>175</td>\n",
       "      <td>0.033149</td>\n",
       "      <td>0.966851</td>\n",
       "      <td>3.314917</td>\n",
       "      <td>96.685083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virginia</th>\n",
       "      <td>4</td>\n",
       "      <td>179</td>\n",
       "      <td>0.022099</td>\n",
       "      <td>0.988950</td>\n",
       "      <td>2.209945</td>\n",
       "      <td>98.895028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kansas</th>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>0.994475</td>\n",
       "      <td>0.552486</td>\n",
       "      <td>99.447514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wyoming</th>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.552486</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Frequency  Cumulative Frequency  Relative Frequency  \\\n",
       "State                                                             \n",
       "California        119                   119            0.657459   \n",
       "Nevada             17                   136            0.093923   \n",
       "Arizona            11                   147            0.060773   \n",
       "Oregon             11                   158            0.060773   \n",
       "Colorado           11                   169            0.060773   \n",
       "Utah                6                   175            0.033149   \n",
       "Virginia            4                   179            0.022099   \n",
       "Kansas              1                   180            0.005525   \n",
       "Wyoming             1                   181            0.005525   \n",
       "\n",
       "            Cumulative Relative Freq.  Relative Freq. [%]  \\\n",
       "State                                                       \n",
       "California                   0.657459           65.745856   \n",
       "Nevada                       0.751381            9.392265   \n",
       "Arizona                      0.812155            6.077348   \n",
       "Oregon                       0.872928            6.077348   \n",
       "Colorado                     0.933702            6.077348   \n",
       "Utah                         0.966851            3.314917   \n",
       "Virginia                     0.988950            2.209945   \n",
       "Kansas                       0.994475            0.552486   \n",
       "Wyoming                      1.000000            0.552486   \n",
       "\n",
       "            Cumulative Freq. [%]  \n",
       "State                             \n",
       "California             65.745856  \n",
       "Nevada                 75.138122  \n",
       "Arizona                81.215470  \n",
       "Oregon                 87.292818  \n",
       "Colorado               93.370166  \n",
       "Utah                   96.685083  \n",
       "Virginia               98.895028  \n",
       "Kansas                 99.447514  \n",
       "Wyoming               100.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdt_2 = get_fdt(df['State'], value_counts=True)    \n",
    "cumulative_pcts = fdt_2['Cumulative Freq. [%]']\n",
    "top_3_pct = cumulative_pcts.iloc[min(2, len(cumulative_pcts)-1)]\n",
    "\n",
    "labels = [f\"{fdt_2.iloc[ix, 0]} ({fdt_2.iloc[ix, -2]:.1f} %)\" for ix in range(fdt_2.shape[0])]\n",
    "print(labels)\n",
    "\n",
    "for iloc_ix in range(len(cumulative_pcts)):\n",
    "    print(f\"cumulative_pcts.iloc[{iloc_ix}] = {cumulative_pcts.iloc[iloc_ix]}\")\n",
    "\n",
    "display(len(cumulative_pcts))\n",
    "display(top_3_pct)\n",
    "fdt_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822d6309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc319fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
